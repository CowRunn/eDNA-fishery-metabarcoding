## This script was run on Linux
the pipeline starts checking the quality of the reads in the fastq files (i.e., we analyse directly the fastq_pass files we do not perform basecalling)
In the output folder of the MinION sequencing go to the fastq_pass folder 
## For each sequencing run we merge the fastq files in the fastq_pass folder

cat *.fastq > raw_reads_Sample_name.fastq

# Create a directory where to store the reads
mkdir /scratch/b.srm18crx/raw_data/Sample_name_analyses/reads_length_files
cd /scratch/b.srm18crx/raw_data/Sample_name_analyses/reads_length_files

# Checking the quality of the raw reads
NanoPlot --fastq raw_reads_Sample_name.fastq -o output_plot_Sample_name

### 3. sorting the reads by length in different files using NanoFilt (https://github.com/wdecoster/nanofilt), it is possible to filter and retain reads above a certain quality threshold using -q 10
NanoFilt ../raw_reads_Sample_name.fastq -l 198 --maxlength 321 -q 10 > mifish_reads_length_Sample_name.fastq
NanoFilt ../raw_reads_Sample_name.fastqq -l 345 --maxlength 500 -q 10 > coi_reads_length_Sample_name.fastq
NanoFilt ../raw_reads_Sample_name.fastq -l 1800 --maxlength 2040 -q 10  > fish_2kb_reads_length_Sample_name.fastq
NanoFilt ../raw_reads_Sample_name.fastq -l 1800 --maxlength 2400 -q 10 > metazoan_reads_length_Sample_name.fastq

#### Cutadapt to remove the primer regions and retain only reads from which the primers were removed.
mkdir /scratch/b.srm18crx/raw_data/Sample_name_analyses/cut_primers
cd /scratch/b.srm18crx/raw_data/Sample_name_analyses/cut_primers

##mifish
cutadapt -g GTCGGTAAAACTCGTGCCAGC...CAAACTGGGATTAGATACCCCACTATG -o mifish_for_Sample_name.fastq ../reads_length_files/mifish* -e 0.2 -m 160 -M 180 --discard-untrimmed
cutadapt -g CATAGTGGGGTATCTAATCCCAGTTTG...GCTGGCACGAGTTTTACCGAC -o mifish_reverse_Sample_name.fastq ../reads_length_files/mifish* -e 0.2 -m 160 -M 180 --discard-untrimmed
mkdir final_reads
cat mifish_*.fastq > final_reads/reads_mifish_Sample_name.fastq

## coi
cutadapt -g GGWACWRGWTGRACWNTNTAYCCYCC...TGRTTYTTYGGNCAYCCNGARGTNTA -o coi_for_Sample_name.fastq ../reads_length_files/coi* -e 0.2 -m 293 -M 333 --discard-untrimmed
cutadapt -g TANACYTCNGGRTGNCCRAARAAYCA...GGRGGRTANANWGTYCAWCYWGTWCC -o coi_reverse_Sample_name.fastq ../reads_length_files/coi* -e 0.2 -m 293 -M 333 --discard-untrimmed
cat coi_*.fastq > final_reads/reads_coi_Sample_name.fastq

## metazoan
cutadapt -g GTGCCAGCHNHHGCGGTYA...ACRTGAKYTGAGTTCARAYCGG -o metazoan_for_Sample_name.fastq ../reads_length_files/metazoan* -e 0.2 -m 1850 -M 2400 --discard-untrimmed
cutadapt -g CCGRTYTGAACTCARMTCAYGT...TRACCGCDDNDGCTGGCAC -o metazoan_reverse_Sample_name.fastq ../reads_length_files/metazoan* -e 0.2 -m 1850 -M 2400 --discard-untrimmed
cat metazoan_*.fastq > final_reads/reads_metazoan_Sample_name.fastq

## fish2 kb
cutadapt -g GGATTAGATACCCYACTATGC...CTAGGGATAACAGCGCAATC -o fish_for_Sample_name.fastq ../reads_length_files/fish* -e 0.2 -m 1900 -M 1995 --discard-untrimmed
cutadapt -g GATTGCGCTGTTATCCCTAG...GCATAGTRGGGTATCTAATCC -o fish_reverse_Sample_name.fastq ../reads_length_files/fish* -e 0.2 -m 1900 -M 1995 --discard-untrimmed
cat fish_*.fastq > final_reads/reads_fish_Sample_name.fastq

mv final_reads ../

## At this point the reads are ready for taxonomic assignment! We create four marker-specific folders and store the reads from each marker into the correct folder as MetONTIIME will be run in each folder
######## Taxonomic assignment using MetONTIIME https://github.com/MaestSi/MetONTIIME
nohup ./MetONTIIME.sh -w /home/saram/sda_HDD1/saram/ont_analysis/final_reads/coi_reads/coi_all_94 -f /home/saram/sda_HDD1/saram/ont_analysis/final_reads/coi_reads/coi_all_94/metadata.tsv -s /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_sequence.qza -t /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_taxonomy.qza -n 12 -c Blast -m 3 -q 0.8 -i 0.94 &
nohup ./MetONTIIME.sh -w /home/saram/sda_HDD1/saram/ont_analysis/final_reads/mifish_reads/mifish_all_94/ -f /home/saram/sda_HDD1/saram/ont_analysis/final_reads/mifish_reads/mifish_all_94/metadata.tsv -s /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_sequence.qza -t /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_taxonomy.qza -n 12 -c Blast -m 3 -q 0.9 -i 0.94 &
nohup ./MetONTIIME.sh -w /home/saram/sda_HDD1/saram/ont_analysis/replicates_final_reads/metazoan_replicates/metazoan_all_94 -f /home/saram/sda_HDD1/saram/ont_analysis/final_reads/metazoan_reads/metazoan_all_94/metadata.tsv -s /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_sequence.qza -t /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_taxonomy.qza -n 12 -c Blast -m 3 -q 0.2 -i 0.94 &
nohup ./MetONTIIME.sh -w /home/saram/sda_HDD1/saram/ont_analysis/final_reads/fish_reads/fish_all_94 -f /home/saram/sda_HDD1/saram/ont_analysis/final_reads/fish_reads/fish_all_94/metadata.tsv -s /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_sequence.qza -t /mnt/sda_HDD1/saram/NS_fish_database_unique/clean_unique_taxonomy.qza -n 12 -c Blast -m 3 -q 0.2 -i 0.94 &
